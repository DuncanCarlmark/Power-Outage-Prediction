{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Outages\n",
    "* **See the main project notebook for instructions to be sure you satisfy the rubric!**\n",
    "* See Project 03 for information on the dataset.\n",
    "* A few example prediction questions to pursue are listed below. However, don't limit yourself to them!\n",
    "    * Predict the severity (number of customers, duration, or demand loss) of a major power outage.\n",
    "    * Predict the cause of a major power outage.\n",
    "    * Predict the number and/or severity of major power outages in the year 2020.\n",
    "    * Predict the electricity consumption of an area.\n",
    "\n",
    "Be careful to justify what information you would know at the \"time of prediction\" and train your model using only those features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Findings\n",
    "\n",
    "\n",
    "### Introduction\n",
    "For this assignment the prediction problem that we are trying to solve is determining the duration of a power outage based on the available data in the outages dataset. In order to compute our predicted values we are using a multiple feature LinearRegression model. We will be using this model to predict the OUTAGE.DURATION variable in the dataset, and our goal is to be able to predict the value of OUTAGE.DURATION with >50% accuracy.\n",
    "\n",
    "### Baseline Model\n",
    "Our baseline model runs off of a sligtly cleaned up dataset. Essentially all we have done at this point is dropped \"OUTAGE.START\", \"OUTAGE.DURATION\", \"OUTAGE.RESTORATION\". We removed the start and restoration columns because we felt that including these would simplify the problem at hand to a point at which it was trivial. The duration coulumn was removed for obvious reasons.\n",
    "\n",
    "As for the data that remained, we simply left the numeric values as is and one-hot encoded all remaining categorical variables. However we did not make any distinction between numeric columns that were technically categorical variable and numeric columns that were simply quantitiative. For example, the month and day columns were left as if they were quantitative and were not one hot encoded.\n",
    "\n",
    "In the end we had:\n",
    "\n",
    "Nominal: 9\n",
    "Ordinal: 4\n",
    "Quantitiative: 41\n",
    "\n",
    "To assess the performance of our model we decided to use linear regression score. We believe that this is a good metric for our performance as it allows us to understand how much of the variance of our data we are accounting for in our model. Since we are doing Regression and not Classification it would not make much sense to use the literall accuracy of our model to determine its performance.\n",
    "\n",
    "The score of our baseline model was absolute garbage at: -0.4929976470442452\n",
    "\n",
    "\n",
    "### Final Model\n",
    "After lots of trial and error, we settled down on two models. The better of the two being our \"Attempt 2\".\n",
    "\n",
    "We first began by determining all of the features we wanted to engineer that we thought would have a significant impact on our model. The next step was adding them to the model among the mountains of other features already present. We also graphed scatter plots of all the features that we could with our cleaned outages data so that we could see if there was any obvious correlation between any of the available factors and the OUTAGE.DURATION. However, because we did not see any obvious answers from this EDA we continued to treat all of the preexistant features the same. We were not getting the performance out of our first attempt that we wanted and we decided that this might be due to the excess of quantitative features present at the end of the outages dataset. These features are mostly state specific statistics for states and are essentially just nominal variables as far as the model is concerend. \n",
    "\n",
    "In our second model, we selected specific features to narrow down the scope of our model and provide more emphasis on our engineered features. Removing the excess quantitative features did not have as significant of an impact as we thought it would (probably because we were running PCA in each of these models), but our second model came out with a slightly higher score at 0.23495832991235685. Unfortunately neither of our models came close to our goal of at least a .5 score so they're just slightly cleaned up garbage\n",
    "\n",
    "Engineered Features:\n",
    "\n",
    "QUARTER: The quarter of the year that the outage occurred in\n",
    "- There could be a relation between the period of the year an outage occurs in and how long it takes to resolve it\n",
    "\n",
    "OUTAGE.START: The date that the outage started on represented as a string\n",
    "- Outages that start at different periods of time might take longer to resolve\n",
    "\n",
    "DAY.OF.WEEK: Numeric representation of M T W Th F Sat Sun\n",
    "- Outages might take longer to resolve on weekends or specific weekdays\n",
    "\n",
    "CUSTOMER.PROPORTION.AFFECTED: CUSTOMERS.AFFECTED / TOTAL.CUSTOMERS\n",
    "- Outages that affect a larger portion of customers might be resolved faster as they are more impactful on business\n",
    "\n",
    "CUSTOMER.VALUE: CUSTOMERS.AFFECTED / TOTAL.SALES\n",
    "- Outages that affect higher paying customers might be resolved faster as they are more impactful on business\n",
    "\n",
    "HOUR: Hour of the day that an outage occurs during, 24 hour time\n",
    "- Outages that occur late at night or early in the morning might take more time to address\n",
    "\n",
    "\n",
    "We chose a LinearRegression model because we wanted to predict quantitative variable and believed that this would the best model to do so with large amounts of features.\n",
    "\n",
    "### Fairness Evaluation\n",
    "\n",
    "For our fairness test, since we were not using a classifier variable to predict a category we decided to use a hypothesis test instead of a permutation test. To be completely honest we didn't really know how to set up a permutationt test for this situation since our predicted variable wasnt really a category. So to the best of our ability we developed a hypothesis test to see if our model performed better/worse for specific periods of the year (months).\n",
    "\n",
    "Null: Our model performs fairly for all months, and any poor performance for a month is due to chance\n",
    "\n",
    "Alternate: Our model performs unfairly for specific months \n",
    "\n",
    "For our hypothesis test we decided to use the average R^2 score across 12 months as a statistic to see if the incredibly poor performance for most of the dataset was just chance or if our model was not performing fairly for the majority of months in the year. For our test statistics we randomly sampled 1/12th of the dataset 12 times to simulate random values for each month.\n",
    "\n",
    "In the end our hypothesis test showed us that 33.6% (p-val .336) of the time when months are composed of rows randomly sampled amongst the dataset, our model performance per month on average worsens. Inversely, our model gets better on average the other 77% of the time. We believe that this means our model is so inconsistient that even though it performs unfairly for certain months, that unfairness is not consistient and is only caused by the poor quality of our underdeveloped model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bf3b3432e950>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_columns'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m999\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing and Cleaning the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a permanent copy of original data to refrain from reading excel file constantly\n",
    "temp = pd.read_excel(\"outage.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>U.S._STATE</th>\n",
       "      <th>POSTAL.CODE</th>\n",
       "      <th>NERC.REGION</th>\n",
       "      <th>CLIMATE.REGION</th>\n",
       "      <th>ANOMALY.LEVEL</th>\n",
       "      <th>CLIMATE.CATEGORY</th>\n",
       "      <th>OUTAGE.START.DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>POPPCT_URBAN</th>\n",
       "      <th>POPPCT_UC</th>\n",
       "      <th>POPDEN_URBAN</th>\n",
       "      <th>POPDEN_UC</th>\n",
       "      <th>POPDEN_RURAL</th>\n",
       "      <th>AREAPCT_URBAN</th>\n",
       "      <th>AREAPCT_UC</th>\n",
       "      <th>PCT_LAND</th>\n",
       "      <th>PCT_WATER_TOT</th>\n",
       "      <th>PCT_WATER_INLAND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>normal</td>\n",
       "      <td>2011-07-01 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>73.27</td>\n",
       "      <td>15.28</td>\n",
       "      <td>2279</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.5927</td>\n",
       "      <td>8.40733</td>\n",
       "      <td>5.47874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>normal</td>\n",
       "      <td>2014-05-11 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>73.27</td>\n",
       "      <td>15.28</td>\n",
       "      <td>2279</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.5927</td>\n",
       "      <td>8.40733</td>\n",
       "      <td>5.47874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>cold</td>\n",
       "      <td>2010-10-26 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>73.27</td>\n",
       "      <td>15.28</td>\n",
       "      <td>2279</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.5927</td>\n",
       "      <td>8.40733</td>\n",
       "      <td>5.47874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>normal</td>\n",
       "      <td>2012-06-19 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>73.27</td>\n",
       "      <td>15.28</td>\n",
       "      <td>2279</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.5927</td>\n",
       "      <td>8.40733</td>\n",
       "      <td>5.47874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>1.2</td>\n",
       "      <td>warm</td>\n",
       "      <td>2015-07-18 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>73.27</td>\n",
       "      <td>15.28</td>\n",
       "      <td>2279</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.5927</td>\n",
       "      <td>8.40733</td>\n",
       "      <td>5.47874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0 OBS  YEAR MONTH U.S._STATE POSTAL.CODE NERC.REGION      CLIMATE.REGION  \\\n",
       "0   1  2011     7  Minnesota          MN         MRO  East North Central   \n",
       "1   2  2014     5  Minnesota          MN         MRO  East North Central   \n",
       "2   3  2010    10  Minnesota          MN         MRO  East North Central   \n",
       "3   4  2012     6  Minnesota          MN         MRO  East North Central   \n",
       "4   5  2015     7  Minnesota          MN         MRO  East North Central   \n",
       "\n",
       "0 ANOMALY.LEVEL CLIMATE.CATEGORY    OUTAGE.START.DATE  ... POPPCT_URBAN  \\\n",
       "0          -0.3           normal  2011-07-01 00:00:00  ...        73.27   \n",
       "1          -0.1           normal  2014-05-11 00:00:00  ...        73.27   \n",
       "2          -1.5             cold  2010-10-26 00:00:00  ...        73.27   \n",
       "3          -0.1           normal  2012-06-19 00:00:00  ...        73.27   \n",
       "4           1.2             warm  2015-07-18 00:00:00  ...        73.27   \n",
       "\n",
       "0 POPPCT_UC POPDEN_URBAN POPDEN_UC POPDEN_RURAL AREAPCT_URBAN AREAPCT_UC  \\\n",
       "0     15.28         2279    1700.5         18.2          2.14        0.6   \n",
       "1     15.28         2279    1700.5         18.2          2.14        0.6   \n",
       "2     15.28         2279    1700.5         18.2          2.14        0.6   \n",
       "3     15.28         2279    1700.5         18.2          2.14        0.6   \n",
       "4     15.28         2279    1700.5         18.2          2.14        0.6   \n",
       "\n",
       "0 PCT_LAND PCT_WATER_TOT PCT_WATER_INLAND  \n",
       "0  91.5927       8.40733          5.47874  \n",
       "1  91.5927       8.40733          5.47874  \n",
       "2  91.5927       8.40733          5.47874  \n",
       "3  91.5927       8.40733          5.47874  \n",
       "4  91.5927       8.40733          5.47874  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outage = temp.copy()\n",
    "\n",
    "# Drop excess descriptive rows\n",
    "outage = (outage\n",
    "          .drop(np.arange(0, 4), axis=0)\n",
    "          .drop(\"Major power outage events in the continental U.S.\", axis=1)\n",
    "          .reset_index(drop=True)\n",
    "         )\n",
    "\n",
    "# Set columns from leftover row\n",
    "cols = outage.iloc[0].reset_index(drop=True)\n",
    "outage.columns = cols\n",
    "outage = outage.drop([0, 1]).reset_index(drop=True)\n",
    "outage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine into one OUTAGE.START and one OUTAGE.RESTORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>U.S._STATE</th>\n",
       "      <th>POSTAL.CODE</th>\n",
       "      <th>NERC.REGION</th>\n",
       "      <th>CLIMATE.REGION</th>\n",
       "      <th>ANOMALY.LEVEL</th>\n",
       "      <th>CLIMATE.CATEGORY</th>\n",
       "      <th>CAUSE.CATEGORY</th>\n",
       "      <th>...</th>\n",
       "      <th>POPDEN_URBAN</th>\n",
       "      <th>POPDEN_UC</th>\n",
       "      <th>POPDEN_RURAL</th>\n",
       "      <th>AREAPCT_URBAN</th>\n",
       "      <th>AREAPCT_UC</th>\n",
       "      <th>PCT_LAND</th>\n",
       "      <th>PCT_WATER_TOT</th>\n",
       "      <th>PCT_WATER_INLAND</th>\n",
       "      <th>OUTAGE.START</th>\n",
       "      <th>OUTAGE.RESTORATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>normal</td>\n",
       "      <td>severe weather</td>\n",
       "      <td>...</td>\n",
       "      <td>2279</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.5927</td>\n",
       "      <td>8.40733</td>\n",
       "      <td>5.47874</td>\n",
       "      <td>2011-07-01 17:00:00</td>\n",
       "      <td>2011-07-03 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>normal</td>\n",
       "      <td>intentional attack</td>\n",
       "      <td>...</td>\n",
       "      <td>2279</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.5927</td>\n",
       "      <td>8.40733</td>\n",
       "      <td>5.47874</td>\n",
       "      <td>2014-05-11 18:38:00</td>\n",
       "      <td>2014-05-11 18:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>cold</td>\n",
       "      <td>severe weather</td>\n",
       "      <td>...</td>\n",
       "      <td>2279</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.5927</td>\n",
       "      <td>8.40733</td>\n",
       "      <td>5.47874</td>\n",
       "      <td>2010-10-26 20:00:00</td>\n",
       "      <td>2010-10-28 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>normal</td>\n",
       "      <td>severe weather</td>\n",
       "      <td>...</td>\n",
       "      <td>2279</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.5927</td>\n",
       "      <td>8.40733</td>\n",
       "      <td>5.47874</td>\n",
       "      <td>2012-06-19 04:30:00</td>\n",
       "      <td>2012-06-20 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>MN</td>\n",
       "      <td>MRO</td>\n",
       "      <td>East North Central</td>\n",
       "      <td>1.2</td>\n",
       "      <td>warm</td>\n",
       "      <td>severe weather</td>\n",
       "      <td>...</td>\n",
       "      <td>2279</td>\n",
       "      <td>1700.5</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.5927</td>\n",
       "      <td>8.40733</td>\n",
       "      <td>5.47874</td>\n",
       "      <td>2015-07-18 02:00:00</td>\n",
       "      <td>2015-07-19 07:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0 OBS  YEAR MONTH U.S._STATE POSTAL.CODE NERC.REGION      CLIMATE.REGION  \\\n",
       "0   1  2011     7  Minnesota          MN         MRO  East North Central   \n",
       "1   2  2014     5  Minnesota          MN         MRO  East North Central   \n",
       "2   3  2010    10  Minnesota          MN         MRO  East North Central   \n",
       "3   4  2012     6  Minnesota          MN         MRO  East North Central   \n",
       "4   5  2015     7  Minnesota          MN         MRO  East North Central   \n",
       "\n",
       "0 ANOMALY.LEVEL CLIMATE.CATEGORY      CAUSE.CATEGORY  ... POPDEN_URBAN  \\\n",
       "0          -0.3           normal      severe weather  ...         2279   \n",
       "1          -0.1           normal  intentional attack  ...         2279   \n",
       "2          -1.5             cold      severe weather  ...         2279   \n",
       "3          -0.1           normal      severe weather  ...         2279   \n",
       "4           1.2             warm      severe weather  ...         2279   \n",
       "\n",
       "0 POPDEN_UC POPDEN_RURAL AREAPCT_URBAN AREAPCT_UC PCT_LAND PCT_WATER_TOT  \\\n",
       "0    1700.5         18.2          2.14        0.6  91.5927       8.40733   \n",
       "1    1700.5         18.2          2.14        0.6  91.5927       8.40733   \n",
       "2    1700.5         18.2          2.14        0.6  91.5927       8.40733   \n",
       "3    1700.5         18.2          2.14        0.6  91.5927       8.40733   \n",
       "4    1700.5         18.2          2.14        0.6  91.5927       8.40733   \n",
       "\n",
       "0 PCT_WATER_INLAND        OUTAGE.START  OUTAGE.RESTORATION  \n",
       "0          5.47874 2011-07-01 17:00:00 2011-07-03 20:00:00  \n",
       "1          5.47874 2014-05-11 18:38:00 2014-05-11 18:39:00  \n",
       "2          5.47874 2010-10-26 20:00:00 2010-10-28 22:00:00  \n",
       "3          5.47874 2012-06-19 04:30:00 2012-06-20 23:00:00  \n",
       "4          5.47874 2015-07-18 02:00:00 2015-07-19 07:00:00  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean Data by combining date and time columns and converting to datetime objects\n",
    "\n",
    "# Copy data to prevent altering original\n",
    "dirty = outage[[\"OUTAGE.START.DATE\", \"OUTAGE.START.TIME\", \"OUTAGE.RESTORATION.DATE\", \"OUTAGE.RESTORATION.TIME\"]].copy()\n",
    "\n",
    "# Takes one datetime column and one time column and sets the datetime column dependent on\n",
    "# the time column\n",
    "def combineDateAndTime(row, dateCol, timeCol):\n",
    "    \n",
    "    # If the value is not present return NaN\n",
    "    if pd.isnull(row[dateCol]):\n",
    "        return row[dateCol]\n",
    "    \n",
    "    # Otherwise set the values of the datetime obj from the time obj\n",
    "    return row[dateCol].replace(hour = row[timeCol].hour, \n",
    "                                minute = row[timeCol].minute, \n",
    "                                second = row[timeCol].second\n",
    "                                )\n",
    "    \n",
    "# Convert both start and restoration times and add them to the table\n",
    "outage[\"OUTAGE.START\"] = dirty.apply(combineDateAndTime, axis=1, args=[\"OUTAGE.START.DATE\", \"OUTAGE.START.TIME\"])\n",
    "outage[\"OUTAGE.RESTORATION\"] = dirty.apply(combineDateAndTime, axis=1, args=[\"OUTAGE.RESTORATION.DATE\", \"OUTAGE.RESTORATION.TIME\"])\n",
    "outageClean = pd.DataFrame(outage.drop(columns=[\"OUTAGE.START.DATE\", \"OUTAGE.START.TIME\", \"OUTAGE.RESTORATION.DATE\", \"OUTAGE.RESTORATION.TIME\"]))\n",
    "\n",
    "outageClean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Remaining Columns to Appropriate Datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "# Change all values to propper datatypes to run statistics\n",
    "for col in outage.columns:\n",
    "    try:\n",
    "        outageClean[col] = outageClean[col].astype(float)\n",
    "        \n",
    "    # If item cannot be converted to a float keep it\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in numcols:\n",
    "#     try:\n",
    "#         outageClean[outageClean[\"OUTAGE.DURATION\"] < 40000].plot.scatter(x=col, y=\"OUTAGE.DURATION\")\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine what columns are categorical and what columns are not\n",
    "\n",
    "X = outageClean.drop([\"OUTAGE.START\", \"OUTAGE.DURATION\", \"OUTAGE.RESTORATION\"], axis=1)\n",
    "\n",
    "y = outageClean[\"OUTAGE.DURATION\"].fillna(0)\n",
    "\n",
    "\n",
    "types = X.dtypes\n",
    "catcols = types.loc[types == np.object].index\n",
    "numcols = types.loc[types != np.object].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "])\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('catcols', cats, catcols),\n",
    "    ('fillNA', SimpleImputer(strategy='constant', fill_value=0), numcols)\n",
    "])\n",
    "\n",
    "\n",
    "pl = Pipeline([('feats', ct), ('reg', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.25, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4929976470442452"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.fit(X_tr, y_tr)\n",
    "pl.score(X_ts, y_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempt One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a quarter feature\n",
    "def findQuarter(date):\n",
    "    if pd.isnull(date):\n",
    "        return 0\n",
    "    return int(date.quarter)\n",
    "\n",
    "# Make a date feature to onehot encode the date \n",
    "def dateToString(date):\n",
    "    return str(date)\n",
    "\n",
    "# Make a feature that corresponds to MTW...\n",
    "def dayOfTheWeek(date):\n",
    "    return str(date.dayofweek)\n",
    "\n",
    "# Make a feature that corresponds to the proportion of the customers affected by the outage\n",
    "def proportionAffected(row):\n",
    "    return row[\"CUSTOMERS.AFFECTED\"] / row[\"TOTAL.CUSTOMERS\"]\n",
    "\n",
    "# Make a feature that corresponds to the monetary value of the customers that were affected\n",
    "def customerValue(row):\n",
    "    return row[\"CUSTOMERS.AFFECTED\"] * row[\"TOTAL.SALES\"]\n",
    "\n",
    "# Make a feature that corresponds to the hour of the day an outage occurs at\n",
    "def hourOfDay(date):\n",
    "    return date.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "outageCleanFinal = outageClean.copy()\n",
    "\n",
    "outageCleanFinal[\"QUARTER\"] = outageClean[\"OUTAGE.START\"].apply(findQuarter)\n",
    "outageCleanFinal[\"OUTAGE.START\"] = outageClean[\"OUTAGE.START\"].apply(dateToString)\n",
    "outageCleanFinal[\"DAY.OF.WEEK\"] = outageClean[\"OUTAGE.START\"].apply(dayOfTheWeek).iloc[0]\n",
    "outageCleanFinal[\"CUSTOMER.PROPORTION.AFFECTED\"] = outageClean.apply(proportionAffected, axis=1)\n",
    "outageCleanFinal[\"CUSTOMER.VALUE\"] = outageClean.apply(customerValue, axis=1)\n",
    "outageCleanFinal[\"HOUR\"] = outageClean[\"OUTAGE.START\"].apply(hourOfDay).fillna(0)\n",
    "\n",
    "\n",
    "outageCleanFinal = outageCleanFinal.drop(\"POSTAL.CODE\", axis=1)\n",
    "\n",
    "\n",
    "# Set up X and Y data\n",
    "X = outageCleanFinal.drop([\"OUTAGE.DURATION\", \"OUTAGE.RESTORATION\", \"OBS\"], axis=1)\n",
    "X[\"MONTH\"] = X[\"MONTH\"].fillna(0)\n",
    "y = outageCleanFinal[\"OUTAGE.DURATION\"].fillna(0)\n",
    "\n",
    "# Determine what columns are categorical and what are not\n",
    "types = X.dtypes\n",
    "catcols = types.loc[types == np.object].index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "catcols = pd.Series(catcols).append(pd.Series([\"QUARTER\", \"YEAR\", \"OUTAGE.START\", \"MONTH\", \"HOUR\", \"DAY.OF.WEEK\"]\n",
    "                                             )).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='constant', fill_value=\"NULL\")),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "    ('pca', PCA(svd_solver='full', n_components=0.99))\n",
    "\n",
    "])\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('catcols', cats, catcols),\n",
    "])\n",
    "\n",
    "\n",
    "pl = Pipeline([('feats', ct), ('reg', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.25, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22497857007570454"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.fit(X_tr, y_tr)\n",
    "pl.score(X_ts, y_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "outageCleanFinal = outageClean.copy()\n",
    "\n",
    "outageCleanFinal = outageClean[[\"YEAR\", \"MONTH\", \"U.S._STATE\", \"NERC.REGION\", \"CLIMATE.REGION\", \"ANOMALY.LEVEL\", \"CLIMATE.CATEGORY\",\n",
    "                 \"CAUSE.CATEGORY\", \"CUSTOMERS.AFFECTED\", \"TOTAL.PRICE\", \"TOTAL.SALES\", \"POPULATION\", \"OUTAGE.START\", \"OUTAGE.DURATION\"\n",
    "                ]].copy()\n",
    "\n",
    "outageCleanFinal[\"QUARTER\"] = outageClean[\"OUTAGE.START\"].apply(findQuarter)\n",
    "outageCleanFinal[\"OUTAGE.START\"] = outageClean[\"OUTAGE.START\"].apply(dateToString)\n",
    "outageCleanFinal[\"DAY.OF.WEEK\"] = outageClean[\"OUTAGE.START\"].apply(dayOfTheWeek).iloc[0]\n",
    "outageCleanFinal[\"CUSTOMER.PROPORTION.AFFECTED\"] = outageClean.apply(proportionAffected, axis=1)\n",
    "outageCleanFinal[\"CUSTOMER.VALUE\"] = outageClean.apply(customerValue, axis=1)\n",
    "outageCleanFinal[\"HOUR\"] = outageClean[\"OUTAGE.START\"].apply(hourOfDay).fillna(0)\n",
    "outageCleanFinal[\"MONTH\"] = outageClean[\"MONTH\"].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "X = outageCleanFinal.drop(\"OUTAGE.DURATION\", axis=1)\n",
    "y = outageCleanFinal[\"OUTAGE.DURATION\"].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "types = X.dtypes\n",
    "catcols = pd.Series(types.loc[types == np.object].index)\n",
    "\n",
    "catcols = pd.Series(catcols).append(pd.Series([\"QUARTER\", \"YEAR\", \"MONTH\", \"HOUR\", \"DAY.OF.WEEK\", \"OUTAGE.START\"]\n",
    "                                             )).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = Pipeline([\n",
    "    ('imp', SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore', sparse=False)),\n",
    "    ('pca', PCA(svd_solver='full', n_components=0.99))\n",
    "\n",
    "])\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('catcols', cats, catcols),\n",
    "])\n",
    "\n",
    "\n",
    "pl = Pipeline([('feats', ct), ('reg', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.25, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23495832991235685"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.fit(X_tr, y_tr)\n",
    "pl.score(X_ts, y_ts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate training and test data by month to see if there is any difference between model performance on a month by month basis\n",
    "\n",
    "scoresPerMonth = []\n",
    "\n",
    "# Find the score of our model on each separate month of the year\n",
    "for i in np.arange(1, 13):\n",
    "    \n",
    "    monData = outageCleanFinal[outageCleanFinal[\"MONTH\"] == i]\n",
    "    \n",
    "    X = monData.drop(\"OUTAGE.DURATION\", axis=1)\n",
    "    y = monData[\"OUTAGE.DURATION\"].fillna(0)\n",
    "    \n",
    "    X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.25, random_state = 2)\n",
    "\n",
    "    pl.fit(X_tr, y_tr)\n",
    "    scoresPerMonth.append(pl.score(X_ts, y_ts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the results into a dataframe\n",
    "monthList = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \n",
    "             \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "dfFairness = pd.DataFrame(index =monthList , data= {\"SCORE\":scoresPerMonth})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observed Fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>January</td>\n",
       "      <td>-0.944511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>February</td>\n",
       "      <td>-5.474730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>March</td>\n",
       "      <td>-0.784987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>April</td>\n",
       "      <td>0.156092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>May</td>\n",
       "      <td>-2.372941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>June</td>\n",
       "      <td>-0.066275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>July</td>\n",
       "      <td>-0.650450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>August</td>\n",
       "      <td>0.159271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>September</td>\n",
       "      <td>-0.122489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>October</td>\n",
       "      <td>0.403898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>November</td>\n",
       "      <td>-2.089926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>December</td>\n",
       "      <td>-0.014992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SCORE\n",
       "January   -0.944511\n",
       "February  -5.474730\n",
       "March     -0.784987\n",
       "April      0.156092\n",
       "May       -2.372941\n",
       "June      -0.066275\n",
       "July      -0.650450\n",
       "August     0.159271\n",
       "September -0.122489\n",
       "October    0.403898\n",
       "November  -2.089926\n",
       "December  -0.014992"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.98350324136128"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(dfFairness)\n",
    "obsvMeanFairness = np.mean(scoresPerMonth)\n",
    "obsvMeanFairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Hypothesis Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.336"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for j in range(1000):\n",
    "    scoresPerMonth = []\n",
    "\n",
    "    # Find the score of our model on each separate month of the year\n",
    "    for i in np.arange(1, 13):\n",
    "\n",
    "        monData = outageCleanFinal.sample(frac=(1/12), replace=True)\n",
    "\n",
    "        X = monData.drop(\"OUTAGE.DURATION\", axis=1)\n",
    "        y = monData[\"OUTAGE.DURATION\"].fillna(0)\n",
    "\n",
    "        X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.25, random_state = 2)\n",
    "\n",
    "        pl.fit(X_tr, y_tr)\n",
    "        scoresPerMonth.append(pl.score(X_ts, y_ts))\n",
    "        \n",
    "    results.append(np.mean(scoresPerMonth))\n",
    "\n",
    "(results <= obsvMeanFairness).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
